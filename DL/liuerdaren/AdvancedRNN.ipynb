{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee1cf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import gzip\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1896a2fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 100\n",
    "N_CHARS = 128\n",
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba2528a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing for 100 epochs...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'create_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/2001077860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0macc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0macc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/516040458.py\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcountries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16484/516040458.py\u001b[0m in \u001b[0;36mmake_tensors\u001b[1;34m(names, countries)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mseq_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mcountries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mname2list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    classifier = RNNClassifier(N_CHARS,HIDDEN_SIZE,N_COUNTRY,N_LAYER)\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier.to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(), lr = 0.001)\n",
    "    \n",
    "    start = time.time()\n",
    "    print(\"Traing for %d epochs...\" % N_EPOCHS)\n",
    "    acc_list = []\n",
    "    for epoch in range(1, N_EPOCHS + 1):\n",
    "        trainModel()\n",
    "        acc = testModel()\n",
    "        acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06e07f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self,is_train_set=True):\n",
    "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz'\n",
    "        with gzip.open(filename,'rt') as f:\n",
    "            reader = csv.reader(f)\n",
    "            rows = list(reader)\n",
    "        self.names = [row[0] for row in rows]\n",
    "        self.len = len(self.names)\n",
    "        self.countries = [row[1] for row in rows]\n",
    "        self.country_list = list(sorted(set(self.countries)))\n",
    "        self.country_dict = self.getCountryDict()\n",
    "        self.country_num = len(self.country_list)\n",
    "    def __getitem__(self, index):\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list, 0):\n",
    "            country_dict[country_name] = idx\n",
    "        return country_dict\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n",
    "\n",
    "trainset = NameDataset(is_train_set = True)\n",
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "testset = NameDataset(is_train_set = True)\n",
    "testloader = DataLoader(testset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "N_COUNTRY = trainset.getCountriesNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e29ea9",
   "metadata": {},
   "source": [
    "N_COUNTRY is the output size of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53914b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers = 1, bidirectional = True):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
    "    def _init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers * self.n_directions, batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)\n",
    "    def forward(self, input, seq_lengths):\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "        \n",
    "        hidden = self._init_hidden(vatch_size)\n",
    "        embedding = self.embedding(input)\n",
    "        \n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths)\n",
    "        \n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1],hidden[-2]],dim = 1)\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    seq_tensor = torch.zeros(len(name_sequences),seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim = 0, descending = True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "    return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)\n",
    "def name2list(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)\n",
    "def trainModel():\n",
    "    total_loss = 0\n",
    "    for i, (names,countries) in enumerate(trainloader, 1):\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "        output = classifier(inputs, seq_lengths)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i%10 == 0:\n",
    "            print(f'[{time_since(start)}] Epoch {epoch}',end='')\n",
    "            print(f'[{i * len(inputs)} / {len(trainset)}] Epoch {epoch}',end='')\n",
    "            print(f'loss = {total_loss / (i * len(inputs))}')\n",
    "        return total_loss\n",
    "def create_tensor():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93228c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf96db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
